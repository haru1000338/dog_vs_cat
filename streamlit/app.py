import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
import sys
import tempfile
from PIL import Image
import io

# predict.pyã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append('..')
from predict import main as predict_image

def search_google_images(query, num_images=10):
    """Googleç”»åƒæ¤œç´¢ã®çµæœã‚’å–å¾—ã™ã‚‹"""
    search_url = f"https://www.google.com/search?q={query}&tbm=isch"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        response = requests.get(search_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # ç”»åƒURLã‚’æŠ½å‡º
        img_tags = soup.find_all('img')
        img_urls = []

        for img in img_tags:
            src = img.get('src')
            if src and src.startswith('http'):
                img_urls.append(src)
                if len(img_urls) >= num_images:
                    break

        return img_urls
    except Exception as e:
        st.error(f"ç”»åƒæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

def download_image(url):
    """URLã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        # ç”»åƒã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
            tmp_file.write(response.content)
            return tmp_file.name
    except Exception as e:
        st.error(f"ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ãƒ‘ã‚¹
sample_images = [
    "results/sample1.jpg",
    "results/sample2.jpg",
    "results/sample3.jpg"
]

# Streamlitã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
st.title("ğŸ±ğŸ¶ çŠ¬ãƒ»çŒ«ç”»åƒåˆ†é¡ã‚¢ãƒ—ãƒª")
st.write("Googleç”»åƒæ¤œç´¢ã§ç”»åƒã‚’é¸æŠã—ã¦ã€çŠ¬ã‹çŒ«ã‹ã‚’åˆ†é¡ã—ã¾ã™ï¼")

# æ¤œç´¢ã‚¯ã‚¨ãƒªã®å…¥åŠ›
search_query = st.text_input("æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value="dog cat")

if st.button("ç”»åƒã‚’æ¤œç´¢"):
    if search_query:
        with st.spinner("ç”»åƒã‚’æ¤œç´¢ä¸­..."):
            img_urls = search_google_images(search_query)

        if img_urls:
            st.success(f"{len(img_urls)}æšã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")
        else:
            st.warning("ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            img_urls = sample_images

        # ç”»åƒã‚’è¡¨ç¤ºï¼ˆ3åˆ—ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
        cols = st.columns(3)
        for i, url in enumerate(img_urls):
            col = cols[i % 3]
            with col:
                try:
                    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‹æ¤œç´¢çµæœã‹ã§å‡¦ç†ã‚’åˆ†ã‘ã‚‹
                    if url.startswith("http"):
                        st.image(url, width=200)
                        temp_file = download_image(url)
                    else:
                        st.image(url, width=200)
                        temp_file = url

                    # åˆ†é¡ãƒœã‚¿ãƒ³
                    if st.button(f"åˆ†é¡ã™ã‚‹", key=f"classify_{i}"):
                        with st.spinner("åˆ†é¡ä¸­..."):
                            if temp_file:
                                try:
                                    # åˆ†é¡ã‚’å®Ÿè¡Œ
                                    prediction, probability = predict_image(temp_file)

                                    if prediction and probability:
                                        # çµæœã‚’è¡¨ç¤º
                                        st.success(f"äºˆæ¸¬çµæœ: **{prediction}**")
                                        st.info(f"ç¢ºç‡: {probability:.4f}")

                                        # åˆ†é¡ã•ã‚ŒãŸç”»åƒã‚’å†è¡¨ç¤º
                                        st.image(url, caption=f"äºˆæ¸¬: {prediction} (ç¢ºç‡: {probability:.4f})", width=300)
                                    else:
                                        st.error("åˆ†é¡ã«å¤±æ•—ã—ã¾ã—ãŸ")

                                finally:
                                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                                    if url.startswith("http") and os.path.exists(temp_file):
                                        os.unlink(temp_file)
                            else:
                                st.error("ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")

                except Exception as e:
                    st.error(f"ç”»åƒã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
st.markdown("---")
st.markdown("### ä½¿ç”¨æ–¹æ³•")
st.markdown("""
1. ä¸Šã®å…¥åŠ›æ¬„ã«æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
2. ã€Œç”»åƒã‚’æ¤œç´¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
3. è¡¨ç¤ºã•ã‚ŒãŸç”»åƒã®ä¸­ã‹ã‚‰åˆ†é¡ã—ãŸã„ç”»åƒã®ã€Œåˆ†é¡ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
4. çŠ¬ã‹çŒ«ã‹ã®äºˆæ¸¬çµæœã¨ç¢ºç‡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
""")